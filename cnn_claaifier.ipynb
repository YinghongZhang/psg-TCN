{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10426\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms as T\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plot\n",
    "from data.ml_dataset import BODataSet\n",
    "from data.cnn_dataset import BloodOxyen\n",
    "from models.tcn import TCN\n",
    "from models.google_net import GoogleNet\n",
    "from models.nasnet import NASNET\n",
    "from models.vgg16 import vgg16\n",
    "from models.dense import DenseNet\n",
    "from models.resnet import ResNet\n",
    "from models.psgnet import PSGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 神经网络参数\n",
    "root = './data/train'\n",
    "batch_size = 4\n",
    "input_channels = 1\n",
    "n_classes = 3\n",
    "seq_length = int(90 / input_channels)\n",
    "epochs = 50\n",
    "steps = 0\n",
    "levels = 8\n",
    "nhid = 256\n",
    "dropout = 0.05\n",
    "channel_sizes = [nhid] * levels\n",
    "kernel_size = 3\n",
    "lr = 0.001\n",
    "optim = \"SGD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算F1 score 准确率 召回率\n",
    "def score(Y, pre_Y):\n",
    "    print(\"Precision_score: %.1f \" % (metrics.precision_score(Y, pre_Y, average='weighted')*100))\n",
    "    print(\"recall_score: %.1f \" % (metrics.recall_score(Y, pre_Y, average='weighted')*100))\n",
    "    print(\"f1_score: %.1f \" % (metrics.f1_score(Y, pre_Y, average='weighted')*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "train_set = BloodOxyen(root=root, train=True, extend=False)\n",
    "val_set = BloodOxyen(root=root, train=False, extend=False)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([101.0, 15.0, 8.0], 86)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.class_total, len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\F\\psg-machine-learning-TCN\\models\\google_net.py:107: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  nn.init.xavier_uniform(m.weight)\n",
      "C:\\F\\psg-machine-learning-TCN\\models\\dense.py:104: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight.data)\n"
     ]
    }
   ],
   "source": [
    "# 初始化网路，verbose 参数决定运行时是否print网络规模（输入输出层数）\n",
    "verbose = False\n",
    "gn_model = GoogleNet(input_channels, n_classes, verbose=verbose)\n",
    "na_model = NASNET(input_channels, n_classes, verbose=verbose)\n",
    "vgg_model = vgg16(num_classes=3, verbose=verbose)\n",
    "ds_model = DenseNet(verbose=verbose)\n",
    "re_model = ResNet(3, verbose=verbose)\n",
    "tcn_model = TCN(input_channels, n_classes, channel_sizes, kernel_size=kernel_size, dropout=dropout)\n",
    "psg_model = PSGNet(1, 3, verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调整学习率函数\n",
    "def adjust_learning_rate(lr, optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = lr * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10426\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision_score: 66.6 \n",
      "recall_score: 81.6 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10426\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 73.3 \n",
      "Epoch 0. Train Loss: 0.17197611529466716 \n",
      " Accuracy of network on 38 events: 81.6%\n",
      "Accuracy of network on 7 abevents: 0.0%\n",
      "Accuracy on 31 normal events: 100.0%\n",
      "Accuracy on 2 hypopnea events: 0.0%\n",
      "Accuracy on 5 apnea events: 0.0% \n",
      "\n",
      "Precision_score: 66.6 \n",
      "recall_score: 81.6 \n",
      "f1_score: 73.3 \n",
      "Epoch 1. Train Loss: 0.15910030658854996 \n",
      " Accuracy of network on 38 events: 81.6%\n",
      "Accuracy of network on 7 abevents: 0.0%\n",
      "Accuracy on 31 normal events: 100.0%\n",
      "Accuracy on 2 hypopnea events: 0.0%\n",
      "Accuracy on 5 apnea events: 0.0% \n",
      "\n",
      "Precision_score: 66.6 \n",
      "recall_score: 81.6 \n",
      "f1_score: 73.3 \n",
      "Epoch 2. Train Loss: 0.14785234699415606 \n",
      " Accuracy of network on 38 events: 81.6%\n",
      "Accuracy of network on 7 abevents: 0.0%\n",
      "Accuracy on 31 normal events: 100.0%\n",
      "Accuracy on 2 hypopnea events: 0.0%\n",
      "Accuracy on 5 apnea events: 0.0% \n",
      "\n",
      "Precision_score: 70.2 \n",
      "recall_score: 81.6 \n",
      "f1_score: 75.5 \n",
      "Epoch 3. Train Loss: 0.13560882297366164 \n",
      " Accuracy of network on 38 events: 81.6%\n",
      "Accuracy of network on 7 abevents: 0.0%\n",
      "Accuracy on 31 normal events: 100.0%\n",
      "Accuracy on 2 hypopnea events: 0.0%\n",
      "Accuracy on 5 apnea events: 0.0% \n",
      "\n",
      "Precision_score: 66.6 \n",
      "recall_score: 81.6 \n",
      "f1_score: 73.3 \n",
      "Epoch 4. Train Loss: 0.13437251452096674 \n",
      " Accuracy of network on 38 events: 81.6%\n",
      "Accuracy of network on 7 abevents: 0.0%\n",
      "Accuracy on 31 normal events: 100.0%\n",
      "Accuracy on 2 hypopnea events: 0.0%\n",
      "Accuracy on 5 apnea events: 0.0% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select a model and train\n",
    "\n",
    "# some arguments for training: loss, epoch, accuracy\n",
    "model = re_model\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = getattr(torch.optim, optim)(model.parameters(), lr=lr)\n",
    "classes = ('normal', 'hypopnea', 'apnea')\n",
    "class_total = [0, 0, 0]\n",
    "class_correct = [0, 0, 0]\n",
    "train_loss = 0\n",
    "best_loss = 100\n",
    "best_acc = []\n",
    "epochs=5\n",
    "\n",
    "for ep in range(epochs):\n",
    "    # record prediction results\n",
    "    class_total = list(0. for i in range(3))\n",
    "    class_correct = list(0. for i in range(3))\n",
    "    train_loss = 0\n",
    "    best_loss = 100\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        if data.shape[0] == 1:\n",
    "            continue\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # validation\n",
    "    numpy_Y = np.array([])\n",
    "    numpy_pred = np.array([])\n",
    "    for seqs, labels in val_loader:\n",
    "        output = model(seqs)\n",
    "        _,prediction = torch.max(output.data, 1)\n",
    "        pre = (labels == prediction.data)\n",
    "        numpy_Y = np.concatenate((numpy_Y, labels.numpy()))\n",
    "        numpy_pred = np.concatenate((numpy_pred, prediction.numpy()))\n",
    "        for y_i in range(len(labels)):\n",
    "            label = labels[y_i]\n",
    "            class_total[label] += 1\n",
    "            class_correct[label] += pre[y_i].item()\n",
    "            \n",
    "    score(numpy_Y, numpy_pred)\n",
    "    adjust_learning_rate(lr, optimizer, ep)\n",
    "    accs = []\n",
    "    accs.append(\"Accuracy of network on %d events: %.1f%%\" %(sum(class_total),  sum(class_correct) / sum(class_total) *100))\n",
    "    accs.append(\"Accuracy of network on %d abevents: %.1f%%\" %(class_total[1]+class_total[2], (class_correct[1]+class_correct[2])/(class_total[1]+class_total[2]) *100))\n",
    "    accs.extend([\"Accuracy on %d %s events: %.1f%%\" %(class_total[i], classes[i], class_correct[i] / class_total[i] * 100) for i in range(3)])\n",
    "\n",
    "    train_loss = train_loss/(len(train_set))\n",
    "    # save the best model\n",
    "    if train_loss < best_loss:\n",
    "        best_loss = train_loss\n",
    "        best_acc = accs\n",
    "        torch.save(model.state_dict(), \"./checkpoints/{}_params.pkl\".format(str(model)[:3]))\n",
    "        #log_model(model, optimizer, criterion, sum(class_total), best_loss, accs)\n",
    "    epoch_str = (\"Epoch {}. Train Loss: {}\".format(ep, train_loss))\n",
    "    print(epoch_str, \"\\n\",\"\\n\".join(accs), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN预测结果\n",
    "numpy_Y = np.array([])\n",
    "numpy_pred = np.array([])\n",
    "# 预测结果（每个类别的得分）\n",
    "cnn_pred_test_score = np.array([0, 0, 0])\n",
    "cnn_pred_test_score.shape = (1,3)\n",
    "count = 0\n",
    "# validation dataset\n",
    "for seqs, labels in val_loader:\n",
    "    output = model(seqs)\n",
    "    _,prediction = torch.max(output.data, 1)\n",
    "    pre = (labels == prediction.data)\n",
    "    numpy_Y = np.concatenate((numpy_Y, labels.numpy()))\n",
    "    numpy_pred = np.concatenate((numpy_pred, prediction.numpy()))\n",
    "    cnn_pred_test_score = np.concatenate((cnn_pred_test_score, nn.functional.softmax(output.data, dim=1).numpy()), axis=0)\n",
    "    \n",
    "    #print(nn.functional.softmax(output.data, dim=1).numpy())\n",
    "    for y_i in range(len(labels)):\n",
    "        label = labels[y_i]\n",
    "        class_total[label] += 1\n",
    "        class_correct[label] += pre[y_i].item()\n",
    "\n",
    "cnn_pred_test_score = cnn_pred_test_score[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_pred_train_score = np.array([0, 0, 0])\n",
    "cnn_pred_train_score.shape = (1,3)\n",
    "count = 0\n",
    "# train dataset\n",
    "for seqs, labels in train_loader:\n",
    "    output = model(seqs)\n",
    "    _,prediction = torch.max(output.data, 1)\n",
    "    pre = (labels == prediction.data)\n",
    "    cnn_pred_train_score = np.concatenate((cnn_pred_train_score, nn.functional.softmax(output.data, dim=1).numpy()), axis=0)\n",
    "\n",
    "cnn_pred_train_score = cnn_pred_train_score[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.logger import SimpleLogger\n",
    "\n",
    "init_message = \"xavier_uniform\"\n",
    "\n",
    "total = len(train_set)\n",
    "logger = SimpleLogger(log_path='./log/', log_name='pulse_classifier')\n",
    "\n",
    "    # Log\n",
    "ctime = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()) \n",
    "logs = {\n",
    "    'Logs': '',\n",
    "    \"Time\": ctime,\n",
    "    # Dataset\n",
    "    'Data size': total,\n",
    "    # Net\n",
    "    'Criterion': criterion,\n",
    "    'optimizer': optimizer,\n",
    "    'Net': model,\n",
    "    # Train\n",
    "    'Epochs': 10,\n",
    "    'loss': best_loss,\n",
    "    # Acurracy\n",
    "    'Acurracy': '\\n'.join(accs),\n",
    "    'Init': init_message\n",
    "}\n",
    "\n",
    "logger.log_info(logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.00000000e+02,   9.80000000e+01,   9.88833333e+01,\n",
       "          1.69722222e-01,   4.11973570e-01,   9.90000000e+01,\n",
       "          4.16625892e-03,   1.01129277e+00,   9.91066914e-01,\n",
       "         -8.16832524e-01,   2.25701386e+00,   0.00000000e+00,\n",
       "          6.77966102e-02,  -1.00000000e+00,   0.00000000e+00,\n",
       "          1.31705989e+01,   2.00000000e+00,   1.00000000e+00,\n",
       "          3.00000000e+00,   9.88833333e+01,   1.72598870e-01,\n",
       "          1.00000000e+02,   9.80000000e+01,  -8.16832524e-01,\n",
       "          2.25701386e+00]), 86, 38, [101.0, 15.0, 8.0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = BODataSet(root=root)\n",
    "class_labels = ('normal', 'hypopnea', 'apnea')\n",
    "X, Y = dataset.get_data()\n",
    "# train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.3, random_state=33)\n",
    "train_X, test_X, train_Y, test_Y = X[:int(len(X)*0.7)], X[int(len(X)*0.7):], Y[:int(len(X)*0.7)], Y[int(len(X)*0.7):]\n",
    "train_X[0], len(train_X), len(test_X), dataset.class_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test code \n",
    "def test(clf, X, Y):\n",
    "#     test models for specify dataset\n",
    "    class_labels = ('normal', 'hypopnea', 'apnea')\n",
    "    class_total = [0, 0, 0]\n",
    "    class_correct = [0, 0, 0]\n",
    "    pre_Y = clf.predict(X)\n",
    "    prediction = (pre_Y == Y)\n",
    "    for index in range(len(Y)):\n",
    "        label = Y[index]\n",
    "        class_total[label] += 1\n",
    "        class_correct[label] += prediction[index]\n",
    "    \n",
    "    accs = []\n",
    "    accs.append(\"Total %d events accuracy: %.1f %%\"%(sum(class_total), sum(class_correct) / sum(class_total) *100))\n",
    "    accs.append(\"Total %d abnormal accuracy: %.1f %%\" %(class_total[1]+class_total[2], (class_correct[1]+class_correct[2])/(class_total[1]+class_total[2]) *100))\n",
    "    accs.extend([\"%s %d events accuracy: %.1f %%\" %(class_labels[i], class_total[i], class_correct[i] / class_total[i] *100 if class_total[i] != 0 else -1) for i in range(3)])\n",
    "    print('\\n'.join(accs), \"\\n\")\n",
    "    \n",
    "    \n",
    "    print(\"Precision_score: %.1f \" % (metrics.precision_score(Y, pre_Y, average='weighted')*100))\n",
    "    print(\"recall_score: %.1f \" % (metrics.recall_score(Y, pre_Y, average='weighted')*100))\n",
    "    print(\"f1_score: %.1f \" % (metrics.f1_score(Y, pre_Y, average='weighted')*100))\n",
    "    return pre_Y\n",
    "\n",
    "# compute accuracy\n",
    "def calc_accuracy(Y, pre_Y):\n",
    "    class_labels = ('normal', 'hypopnea', 'apnea')\n",
    "    class_total = [0, 0, 0]\n",
    "    class_correct = [0, 0, 0]\n",
    "    prediction = (pre_Y == Y)\n",
    "    #print(prediction)\n",
    "    for index in range(len(Y)):\n",
    "        label = Y[index]\n",
    "        class_total[label] += 1\n",
    "        class_correct[label] += prediction[index]\n",
    "    \n",
    "    accs = []\n",
    "    accs.append(\"Total %d events accuracy: %.1f %%\"%(sum(class_total), sum(class_correct) / sum(class_total) *100))\n",
    "    accs.append(\"Total %d abnormal accuracy: %.1f %%\" %(class_total[1]+class_total[2], (class_correct[1]+class_correct[2])/(class_total[1]+class_total[2]) *100))\n",
    "    accs.extend([\"%s %d events accuracy: %.1f %%\" %(class_labels[i], class_total[i], class_correct[i] / class_total[i] *100 if class_total[i] != 0 else -1) for i in range(3)])\n",
    "    \n",
    "    print('\\n'.join(accs), \"\\n\")\n",
    "    \n",
    "    print(\"Precision_score: %.1f \" % (metrics.precision_score(Y, pre_Y, average='weighted')*100))\n",
    "    print(\"recall_score: %.1f \" % (metrics.recall_score(Y, pre_Y, average='weighted')*100))\n",
    "    print(\"f1_score: %.1f \" % (metrics.f1_score(Y, pre_Y, average='weighted')*100))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10426\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 35 candidates, totalling 105 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=8)]: Done 105 out of 105 | elapsed:    3.7s finished\n",
      "C:\\Users\\10426\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 38 events accuracy: 81.6 %\n",
      "Total 7 abnormal accuracy: 0.0 %\n",
      "normal 31 events accuracy: 100.0 %\n",
      "hypopnea 2 events accuracy: 0.0 %\n",
      "apnea 5 events accuracy: 0.0 % \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10426\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision_score: 74.4 \n",
      "recall_score: 81.6 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10426\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 77.8 \n",
      "10 0.001\n"
     ]
    }
   ],
   "source": [
    "# train a SVM model\n",
    "svm_clf = svm.SVC()\n",
    "svm_clf = svm.SVC(decision_function_shape='ovo', C=0.001, gamma=0.0001)\n",
    "param_grid = {'C': [1e-3, 1e-2, 1e-1, 1, 10, 100, 1000], 'gamma':[0.0001, 0.001, 0.01, 0.1, 0.3],}\n",
    "\n",
    "svm_clf_cv = GridSearchCV(svm.SVC(decision_function_shape='ovo', kernel='rbf'),param_grid, n_jobs=8, verbose=2, scoring='f1_macro')\n",
    "svm_clf_cv.fit(X,Y)\n",
    "\n",
    "svm_clf = svm.SVC(decision_function_shape='ovo', C=svm_clf_cv.best_params_['C'], gamma=svm_clf_cv.best_params_['gamma'], probability=True)\n",
    "svm_clf.fit(train_X, train_Y)\n",
    "\n",
    "test(svm_clf, test_X, test_Y)\n",
    "\n",
    "\n",
    "print(svm_clf_cv.best_params_['C'], svm_clf_cv.best_params_['gamma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 38 events accuracy: 81.6 %\n",
      "Total 7 abnormal accuracy: 0.0 %\n",
      "normal 31 events accuracy: 100.0 %\n",
      "hypopnea 2 events accuracy: 0.0 %\n",
      "apnea 5 events accuracy: 0.0 % \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10426\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision_score: 74.4 \n",
      "recall_score: 81.6 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10426\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 77.8 \n"
     ]
    }
   ],
   "source": [
    "# get svm predict score\n",
    "import pylab as pl\n",
    "svm_clf.fit(train_X,train_Y)\n",
    "test(svm_clf, test_X, test_Y)\n",
    "len(svm_clf.support_vectors_)\n",
    "svm_pred_train_score = svm_clf.predict_proba(train_X)\n",
    "svm_pred_test_score = svm_clf.predict_proba(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# confusion matrix \n",
    "# https://jakevdp.github.io/PythonDataScienceHandbook/05.07-support-vector-machines.html\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# use seaborn plotting defaults\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pre = svm_clf.predict(test_X)\n",
    "mat = confusion_matrix(test_Y, pre)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=class_labels,\n",
    "            yticklabels=class_labels)\n",
    "# plt.figure()\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');\n",
    "plt.rcParams['figure.dpi'] = 100 #分辨率\n",
    "plt.savefig(\"./cm_svm\")\n",
    "# plt.rcParams.update({'font.size': 40})\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 38 events accuracy: 78.9 %\n",
      "Total 7 abnormal accuracy: 0.0 %\n",
      "normal 31 events accuracy: 96.8 %\n",
      "hypopnea 2 events accuracy: 0.0 %\n",
      "apnea 5 events accuracy: 0.0 % \n",
      "\n",
      "Precision_score: 69.9 \n",
      "recall_score: 78.9 \n",
      "f1_score: 74.2 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.03930679,  0.05602027,  0.1242781 ,\n",
       "        0.01275096,  0.00907853,  0.07234191,  0.03124365,  0.03332294,\n",
       "        0.12156867,  0.        ,  0.00755508,  0.        ,  0.        ,\n",
       "        0.03058606,  0.        ,  0.01456617,  0.00853175,  0.01706187,\n",
       "        0.14321527,  0.01449302,  0.00590457,  0.02708594,  0.23108846])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(clf.best_estimator_.get_params())\n",
    "rf_clf = RandomForestClassifier(max_depth=20, max_features=0.7, criterion='gini', max_leaf_nodes=500, min_samples_leaf=1, min_samples_split=2, n_estimators=10)\n",
    "rf_clf.fit(train_X, train_Y)\n",
    "test(rf_clf, test_X, test_Y)\n",
    "rf_clf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 38 events accuracy: 78.9 %\n",
      "Total 7 abnormal accuracy: 0.0 %\n",
      "normal 31 events accuracy: 96.8 %\n",
      "hypopnea 2 events accuracy: 0.0 %\n",
      "apnea 5 events accuracy: 0.0 % \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10426\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision_score: 74.2 \n",
      "recall_score: 78.9 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10426\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 76.5 \n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'multi:softmax',  # 多分类的问题\n",
    "    'num_class': 3,               # 类别数，与 multisoftmax 并用\n",
    "    'gamma': 0.1,                  # 用于控制是否后剪枝的参数,越大越保守，一般0.1、0.2这样子。\n",
    "    'max_depth': 12,               # 构建树的深度，越大越容易过拟合\n",
    "    'lambda': 2,                   # 控制模型复杂度的权重值的L2正则化项参数，参数越大，模型越不容易过拟合。\n",
    "    'subsample': 0.7,              # 随机采样训练样本\n",
    "    'colsample_bytree': 0.7,       # 生成树时进行的列采样\n",
    "    'min_child_weight': 3,\n",
    "    'silent': 1,                   # 设置成1则没有运行信息输出，最好是设置为0.\n",
    "    'eta': 0.1,                  # 如同学习率\n",
    "    'seed': 1000,\n",
    "    'nthread': 4,                  # cpu 线程数\n",
    "}\n",
    "plst = params.items()\n",
    "\n",
    "dtrain = xgb.DMatrix(train_X, train_Y)\n",
    "d_test_X = xgb.DMatrix(test_X)\n",
    "# model = xgb.train(plst, dtrain, 100)\n",
    "\n",
    "# test(model, d_test_X, test_Y)\n",
    "\n",
    "xgb_clf = XGBClassifier(learning_rate=0.1)\n",
    "xgb_clf.fit(np.array(train_X), train_Y)\n",
    "\n",
    "test(xgb_clf, np.array(test_X), test_Y)\n",
    "xgb_pred_train_score = xgb_clf.predict_proba(np.array(train_X))\n",
    "xgb_pred_test_score = xgb_clf.predict_proba(np.array(test_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 38 events accuracy: 73.7 %\n",
      "Total 7 abnormal accuracy: 0.0 %\n",
      "normal 31 events accuracy: 90.3 %\n",
      "hypopnea 2 events accuracy: 0.0 %\n",
      "apnea 5 events accuracy: 0.0 % \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10426\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision_score: 73.7 \n",
      "recall_score: 73.7 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10426\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 73.7 \n"
     ]
    }
   ],
   "source": [
    "train_data = lgb.Dataset(np.array(train_X), train_Y)\n",
    "test_data = lgb.Dataset(np.array(test_X), label=test_Y)\n",
    "\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'n_estimators': 30,\n",
    "    'objective': 'multiclass',\n",
    "    'max_depth': 50,\n",
    "    'num_class': 3,\n",
    "#     'metric': 'auc',\n",
    "    'learning_rate': 0.1,\n",
    "#     'verbose': 0\n",
    "}\n",
    "\n",
    "lgb_clf = lgb.LGBMClassifier()\n",
    "lgb_clf.fit(train_X, train_Y)\n",
    "# lgb_clf = lgb.train(params, train_data, valid_sets=test_data)\n",
    "\n",
    "y_pred = lgb_clf.predict(test_X)\n",
    "# y_pred = np.array([list(e).index(max(e)) for e in y_pred])\n",
    "\n",
    "calc_accuracy(test_Y, y_pred)\n",
    "lgb_pred_train_score = lgb_clf.predict_proba(train_X)\n",
    "lgb_pred_test_score = lgb_clf.predict_proba(test_X)\n",
    "# bst.save_model('model.txt')\n",
    "# json_model = bst.dump_model()\n",
    "# bst = lgb.Booster(model_file='model.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 38 events accuracy: 81.6 %\n",
      "Total 7 abnormal accuracy: 14.3 %\n",
      "normal 31 events accuracy: 96.8 %\n",
      "hypopnea 2 events accuracy: 0.0 %\n",
      "apnea 5 events accuracy: 20.0 % \n",
      "\n",
      "Precision_score: 83.1 \n",
      "recall_score: 81.6 \n",
      "f1_score: 81.5 \n"
     ]
    }
   ],
   "source": [
    "gbdt_clf = GradientBoostingClassifier(random_state=10)\n",
    "gbdt_clf.fit(train_X, train_Y)\n",
    "\n",
    "test(gbdt_clf, test_X, test_Y)\n",
    "\n",
    "gbdt_pred_train_score = gbdt_clf.predict_proba(train_X)\n",
    "gbdt_pred_test_score = gbdt_clf.predict_proba(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=1, p=5, metric='minkowski')\n",
    "knn_clf.fit(train_X,train_Y)\n",
    "\n",
    "test(knn, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desicion Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(criterion='entropy', max_depth=10, random_state=10)\n",
    "dt_clf.fit(train_X, train_Y)\n",
    "\n",
    "test(dt_clf, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 传统模型自我融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf = VotingClassifier(estimators=[('svm', svm_clf), ('lgb', lgb_clf), ('gbdt', gbdt_clf)])\n",
    "eclf = eclf.fit(np.array(train_X),train_Y)\n",
    "pre_Y = test(eclf, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix \n",
    "# test code for fusion models\n",
    "# https://jakevdp.github.io/PythonDataScienceHandbook/05.07-support-vector-machines.html\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# use seaborn plotting defaults\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pre = eclf.predict(test_X)\n",
    "mat = confusion_matrix(test_Y, pre)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=class_labels,\n",
    "            yticklabels=class_labels)\n",
    "# plt.figure()\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');\n",
    "plt.rcParams['figure.dpi'] = 100 #分辨率\n",
    "plt.savefig(\"./cm_svm\")\n",
    "# plt.rcParams.update({'font.size': 40})\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN和传统模型融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_test_score = np.concatenate((svm_pred_test_score, cnn_pred_test_score), axis=1)\n",
    "fusion_train_score = np.concatenate((svm_pred_train_score, cnn_pred_train_score), axis=1)\n",
    "fusion_train_score = torch.from_numpy(fusion_train_score).float()\n",
    "fusion_test_score = torch.from_numpy(fusion_test_score).float()\n",
    "fusion_train_set = list(zip(fusion_train_score, train_Y))\n",
    "fusion_test_set = list(zip(fusion_test_score, test_Y))\n",
    "\n",
    "fusion_train_score.shape, fusion_test_score.shape,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fusion_network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(fusion_network,self).__init__()\n",
    "        self.linear = nn.Linear(6,3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train the fusion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_train_loader = torch.utils.data.DataLoader(fusion_train_set, batch_size=batch_size, shuffle=True)\n",
    "fusion_val_loader = torch.utils.data.DataLoader(fusion_test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_model = fusion_network()\n",
    "\n",
    "fusion_criterion = torch.nn.CrossEntropyLoss()\n",
    "fusion_optimizer = getattr(torch.optim, optim)(model.parameters(), lr=lr)\n",
    "classes = ('normal', 'hypopnea', 'apnea')\n",
    "best_acc = []\n",
    "\n",
    "for ep in range(epochs):\n",
    "    class_total = list(0. for i in range(3))\n",
    "    class_correct = list(0. for i in range(3))\n",
    "    train_loss = 0\n",
    "    best_loss = 100\n",
    "    for batch_idx, (data, target) in enumerate(fusion_train_loader):\n",
    "        fusion_optimizer.zero_grad()\n",
    "        if data.shape[0] == 1:\n",
    "            continue\n",
    "        output = fusion_model(data)\n",
    "        loss = fusion_criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # validation\n",
    "    numpy_Y = np.array([])\n",
    "    numpy_pred = np.array([])\n",
    "    for seqs, labels in fusion_val_loader:\n",
    "        output = fusion_model(seqs)\n",
    "        _,prediction = torch.max(output.data, 1)\n",
    "        pre = (labels == prediction.data)\n",
    "        numpy_Y = np.concatenate((numpy_Y, labels.numpy()))\n",
    "        numpy_pred = np.concatenate((numpy_pred, prediction.numpy()))\n",
    "        for y_i in range(len(labels)):\n",
    "            label = labels[y_i]\n",
    "            class_total[label] += 1\n",
    "            class_correct[label] += pre[y_i].item()\n",
    "            \n",
    "    score(numpy_Y, numpy_pred)\n",
    "    adjust_learning_rate(lr, fusion_optimizer, ep)\n",
    "    accs = []\n",
    "    accs.append(\"Accuracy of network on %d events: %.1f%%\" %(sum(class_total),  sum(class_correct) / sum(class_total) *100))\n",
    "    accs.append(\"Accuracy of network on %d abevents: %.1f%%\" %(class_total[1]+class_total[2], (class_correct[1]+class_correct[2])/(class_total[1]+class_total[2]) *100))\n",
    "    accs.extend([\"Accuracy on %d %s events: %.1f%%\" %(class_total[i], classes[i], class_correct[i] / class_total[i] * 100) for i in range(3)])\n",
    "\n",
    "    train_loss = train_loss/(len(train_set))\n",
    "    if train_loss < best_loss:\n",
    "        best_loss = train_loss\n",
    "        best_acc = accs\n",
    "        torch.save(fusion_model.state_dict(), \"./checkpoints/cnn_models/{}_params.pkl\".format(str(fusion_model)[:3]))\n",
    "        #log_model(model, optimizer, criterion, sum(class_total), best_loss, accs)\n",
    "    epoch_str = (\"Epoch {}. Train Loss: {}\".format(ep, train_loss))\n",
    "    print(epoch_str, \"\\n\",\"\\n\".join(accs), \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
